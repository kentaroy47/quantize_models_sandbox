{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rnDcTB4MCGyi",
    "outputId": "894188f4-250c-4e1d-8451-b9460594c04e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 17 17:14:22 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 455.45.01    Driver Version: 455.45.01    CUDA Version: 11.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  RTX A6000           On   | 00000000:09:00.0 Off |                  Off |\r\n",
      "| 34%   54C    P8    29W / 240W |     35MiB / 48682MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1264      G   /usr/lib/xorg/Xorg                 21MiB |\r\n",
      "|    0   N/A  N/A      1386      G   /usr/bin/gnome-shell               12MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5bfd7ea1",
    "outputId": "cf51ee51-88e1-4554-b4b2-10526d05484c"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import pandas as pd\n",
    "import network.resnet_orig as resnet\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, RandomSampler, SequentialSampler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "\n",
    "model_names = sorted(name for name in resnet.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "                     and name.startswith(\"resnet\")\n",
    "                     and callable(resnet.__dict__[name]))\n",
    "\n",
    "DATA_DIR = \"train\"\n",
    "print_freq = 50\n",
    "K = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2f9a579"
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "0f47a8d8"
   },
   "outputs": [],
   "source": [
    "from utils.data_utils import get_loader\n",
    "from utils.utils import AverageMeter, accuracy\n",
    "import pandas as pd\n",
    "from network.inference import inference_noise\n",
    "\n",
    "_, val_loader = get_loader(None, inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b4a5560e",
    "outputId": "c46b697c-9fe3-4d58-f99b-94af12815c7a"
   },
   "outputs": [],
   "source": [
    "from network.resnet_orig import resnet20, resnet34\n",
    "K=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>snr</th>\n",
       "      <th>conv1</th>\n",
       "      <th>linear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93.7100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93.0950</td>\n",
       "      <td>0.1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91.8925</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89.8550</td>\n",
       "      <td>0.3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       acc  snr  conv1  linear\n",
       "0  93.7100  0.0   True    True\n",
       "1  93.0950  0.1   True    True\n",
       "2  91.8925  0.2   True    True\n",
       "3  89.8550  0.3   True    True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "modelname = \"resnet20\"\n",
    "checkpoint_dir = f\"checkpoint/{modelname}-ckpt.pth\"\n",
    "inference = inference_noise(modelname, checkpoint_dir, val_loader, K, 4, [0,0.1,0.2,0.3])\n",
    "\n",
    "results = inference.val()\n",
    "\n",
    "#results = inference.val_all([0, 0.1, 0.2, 0.3])\n",
    "    \n",
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"results\", exist_ok=True)\n",
    "df.to_csv(f\"results/{modelname}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scale layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "maveOvaTD5xt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n"
     ]
    }
   ],
   "source": [
    "results2 = []\n",
    "inference = inference_noise(modelname, checkpoint_dir, val_loader, K, 4, [0.4])\n",
    "results2.extend(inference.val(1, 1))\n",
    "results2.extend(inference.val(0.5, 0.5))\n",
    "results2.extend(inference.val(0.25, 0.25))\n",
    "results2.extend(inference.val(0.2, 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'acc': 85.96499992370605, 'snr': 0.4, 'conv1': 1, 'linear': 1},\n",
       " {'acc': 90.91499996032715, 'snr': 0.4, 'conv1': 0.5, 'linear': 0.5},\n",
       " {'acc': 90.83249997863768, 'snr': 0.4, 'conv1': 0.25, 'linear': 0.25},\n",
       " {'acc': 90.97499995422362, 'snr': 0.4, 'conv1': 0.2, 'linear': 0.2}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n",
      "bit width: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'acc': 93.13499996643067, 'snr': 0.1, 'conv1': 1, 'linear': 1},\n",
       " {'acc': 93.32249998474121, 'snr': 0.1, 'conv1': 0.5, 'linear': 0.5},\n",
       " {'acc': 93.34749990844726, 'snr': 0.1, 'conv1': 0.25, 'linear': 0.25}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2 = []\n",
    "inference = inference_noise(modelname, checkpoint_dir, val_loader, K, 4, [0.1])\n",
    "results2.extend(inference.val(1, 1))\n",
    "results2.extend(inference.val(0.5, 0.5))\n",
    "results2.extend(inference.val(0.25, 0.25))\n",
    "results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "PACT_inference",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
