{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bfd7ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import pandas as pd\n",
    "import resnet\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, RandomSampler, SequentialSampler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "\n",
    "model_names = sorted(name for name in resnet.__dict__\n",
    "    if name.islower() and not name.startswith(\"__\")\n",
    "                     and name.startswith(\"resnet\")\n",
    "                     and callable(resnet.__dict__[name]))\n",
    "\n",
    "DATA_DIR = \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fbfe86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from module import ActFn, Conv2d, Linear\n",
    "from torch.autograd import Variable\n",
    "\n",
    "__all__ = ['ResNet', 'resnet20', 'resnet32', 'resnet44', 'resnet56', 'resnet110', 'resnet1202']\n",
    "\n",
    "def _weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    #print(classname)\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight)\n",
    "\n",
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, k=8, expansion=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.k = k\n",
    "        self.expansion = expansion\n",
    "        # self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.conv1 = Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False, bitwidth = k)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.alpha1 = nn.Parameter(torch.tensor(10.))\n",
    "        # self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.conv2 = Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False, bitwidth = k)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.alpha2 = nn.Parameter(torch.tensor(10.))\n",
    "        self.ActFn = ActFn.apply\n",
    "        \n",
    "        if stride != 1 or in_planes != planes:\n",
    "              # original resnet shortcut\n",
    "              self.shortcut = nn.Sequential(\n",
    "                    # nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                    Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                    nn.BatchNorm2d(self.expansion * planes)\n",
    "              )\n",
    "        else: # nothing done if stride or inplanes do not differ\n",
    "          self.shortcut = nn.Sequential()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.ActFn(self.bn1(self.conv1(x)), self.alpha1, self.k)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        # out = F.relu(out)\n",
    "        out = self.ActFn(out, self.alpha2, self.k)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10, K=8):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 16\n",
    "        self.k = K\n",
    "\n",
    "        # self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.conv1 = Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False, bitwidth = 8)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.alpha1 = nn.Parameter(torch.tensor(10.))\n",
    "        self.ActFn = ActFn.apply\n",
    "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1, expansion=1)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2, expansion=1)\n",
    "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2, expansion=1)\n",
    "\n",
    "        # self.linear = nn.Linear(64, num_classes)\n",
    "        self.linear = Linear(64, num_classes, bitwidth = 8)\n",
    "        self.apply(_weights_init)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride, expansion):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride, self.k, expansion))\n",
    "            self.in_planes = planes * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out1 = self.ActFn(self.bn1(self.conv1(x)), self.alpha1, self.k)\n",
    "        out2 = self.layer1(out1)\n",
    "        out3 = self.layer2(out2)\n",
    "        out4 = self.layer3(out3)\n",
    "        out = F.avg_pool2d(out4, out4.size()[3])\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out, out1, out2, out3, out4\n",
    "\n",
    "\n",
    "def resnet20(k=8):\n",
    "    print(\"bit width:\", k)\n",
    "    return ResNet(BasicBlock, [3, 3, 3], K=k)\n",
    "\n",
    "def test(net):\n",
    "    import numpy as np\n",
    "    total_params = 0\n",
    "\n",
    "    for x in filter(lambda p: p.requires_grad, net.parameters()):\n",
    "        total_params += np.prod(x.data.numpy().shape)\n",
    "    print(\"Total number of params\", total_params)\n",
    "    print(\"Total layers\", len(list(filter(lambda p: p.requires_grad and len(p.data.size())>1, net.parameters()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4043192",
   "metadata": {},
   "source": [
    "# Check outputs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1105cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bit width: 3\n",
      "alpha: Parameter containing:\n",
      "tensor(10., device='cuda:0', requires_grad=True)\n",
      "tensor(1.4286, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.       , 1.4285715, 2.857143 ], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check activations\n",
    "bits = 3\n",
    "model = resnet20(bits)\n",
    "model = model.cuda().eval()\n",
    "out, out2, out3, out4, out5 = model.forward(torch.rand([1,3,32,32]).cuda())\n",
    "print(\"alpha:\", model.alpha1)\n",
    "print(model.alpha1/(np.power(2, bits)-1))\n",
    "np.unique(out2.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "44b169e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.        , -0.71428573, -0.4285714 , -0.14285713,  0.1428572 ,\n",
       "        0.42857146,  0.71428573,  1.        ], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check weights\n",
    "weights = model.state_dict()['conv1.weight'].cpu().detach()\n",
    "# quantize\n",
    "from module import DoReFaQuant\n",
    "quantize = DoReFaQuant.apply\n",
    "np.unique(quantize(weights, 3).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052b2371",
   "metadata": {},
   "source": [
    "weights are quantized on-the-fly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f9cdc1",
   "metadata": {},
   "source": [
    "# Load trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfabadde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
