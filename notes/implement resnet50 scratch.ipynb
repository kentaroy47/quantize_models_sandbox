{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "102a7b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09f5e73",
   "metadata": {},
   "source": [
    "https://www.bigdata-navi.com/aidrops/2611/\n",
    "を実装する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5e2c65",
   "metadata": {},
   "source": [
    "![](https://www.bigdata-navi.com/aidrops/wp-content/uploads/2020/03/2-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac8b7b4",
   "metadata": {},
   "source": [
    "# 設計方針\n",
    "* blockを 3x, 4x, 6x, 3x回繰り返す。\n",
    "\n",
    "* 最後にaverage poolする。\n",
    "\n",
    "* res34はvgg34でres50は1x1で小さくしてからconvしてFLOP増加を抑えている。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4484d72",
   "metadata": {},
   "source": [
    "# basic blockを作る"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670593b3",
   "metadata": {},
   "source": [
    "![](https://www.bigdata-navi.com/aidrops/wp-content/uploads/2020/03/3-300x266.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "adcbe88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class block(nn.Module):\n",
    "    def __init__(self, inchannel, outchannel):\n",
    "        super().__init__()\n",
    "        channel = outchannel//4\n",
    "        \n",
    "        # 1x1 conv\n",
    "        self.conv1 = nn.Conv2d(inchannel, channel, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(channel)\n",
    "        self.relu1 = nn.ReLU(True)\n",
    "        \n",
    "        # 3x3 conv\n",
    "        self.conv2 = nn.Conv2d(channel, channel, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(channel)\n",
    "        self.relu2 = nn.ReLU(True)\n",
    "        \n",
    "        # 1x1 conv\n",
    "        self.conv3 = nn.Conv2d(channel, outchannel, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(outchannel)\n",
    "        self.relu3 = nn.ReLU(True)\n",
    "        \n",
    "        # residual\n",
    "        if inchannel == outchannel:\n",
    "            self.shortcut = lambda x: x # just copy\n",
    "        else:\n",
    "            self.shortcut = nn.Conv2d(inchannel, outchannel, 1, padding=0) # 1x1 to adjust channels\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_cpy = x\n",
    "        # 1x1\n",
    "        x = self.relu1(self.bn1(self.conv1(x)))\n",
    "        # 3x3\n",
    "        x = self.relu2(self.bn2(self.conv2(x)))\n",
    "        # 1x1\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        # residual\n",
    "        x += self.shortcut(x_cpy)\n",
    "        x = self.relu3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81286ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 100, 100])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same channels\n",
    "model = block(128, 128)\n",
    "model(torch.rand(1,128,100,100)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27a9af4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 100, 100])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dif channels\n",
    "model = block(64, 128)\n",
    "model(torch.rand(1,64,100,100)).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0de1fa0",
   "metadata": {},
   "source": [
    "# Make basic block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5b8c6700",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50(nn.Module):\n",
    "    def __init__(self, ch=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 1st conv\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3, padding=1, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        # 2nd block 3 times\n",
    "        layers = []\n",
    "        layers += [self._building_block(256, 64)]\n",
    "        layers += [self._building_block(256) for _ in range(2)]\n",
    "        self.block2 = nn.ModuleList(layers)\n",
    "        \n",
    "        # 3rd block 4 times\n",
    "        layers = []\n",
    "        layers += [self._building_block(512, 256)]\n",
    "        layers += [self._building_block(512) for _ in range(3)]\n",
    "        self.block3 = nn.ModuleList(layers)\n",
    "        \n",
    "        # 4rd block 6 times\n",
    "        layers = []\n",
    "        layers += [self._building_block(1024, 512)]\n",
    "        layers += [self._building_block(1024) for _ in range(5)]\n",
    "        self.block4 = nn.ModuleList(layers)\n",
    "        \n",
    "        # 5th block 3 times\n",
    "        layers = []\n",
    "        layers += [self._building_block(2048, 1024)]\n",
    "        layers += [self._building_block(2048) for _ in range(2)]\n",
    "        self.block5 = nn.ModuleList(layers)\n",
    "        \n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(2048, ch)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 1st\n",
    "        x = self.relu1(self.bn1(self.conv1(x)))\n",
    "        \n",
    "        # 2nd\n",
    "        for block in self.block2:\n",
    "            x = block(x)\n",
    "        x = x[:,:,::2,::2]\n",
    "        \n",
    "        # 3rd\n",
    "        for block in self.block3:\n",
    "            x = block(x)\n",
    "        x = x[:,:,::2,::2]\n",
    "        print(x.size())\n",
    "        \n",
    "        # 4th\n",
    "        for block in self.block4:\n",
    "            x = block(x)\n",
    "        x = x[:,:,::2,::2]\n",
    "        \n",
    "        # 5th\n",
    "        for block in self.block5:\n",
    "            x = block(x)\n",
    "        \n",
    "        # fc\n",
    "        x = self.gap(x).squeeze(2).squeeze(2)\n",
    "        x = self.fc(x)        \n",
    "        return x\n",
    "    \n",
    "    def _make_layer(self):\n",
    "        layers = []\n",
    "    \n",
    "    def _building_block(self,\n",
    "                        channel_out,\n",
    "                        channel_in=None):\n",
    "        if channel_in is None:\n",
    "            channel_in = channel_out\n",
    "        return block(channel_in, channel_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ae8a3a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet50(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu1): ReLU()\n",
       "  (block2): ModuleList(\n",
       "    (0): block(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU(inplace=True)\n",
       "      (shortcut): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (1): block(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): block(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (block3): ModuleList(\n",
       "    (0): block(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU(inplace=True)\n",
       "      (shortcut): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (1): block(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): block(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): block(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (block4): ModuleList(\n",
       "    (0): block(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU(inplace=True)\n",
       "      (shortcut): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (1): block(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): block(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): block(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): block(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): block(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (block5): ModuleList(\n",
       "    (0): block(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU(inplace=True)\n",
       "      (shortcut): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (1): block(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): block(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (gap): AdaptiveAvgPool2d(output_size=1)\n",
       "  (fc): Linear(in_features=2048, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet50()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0b20a034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512, 16, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.rand(1,3,128,128)).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1906db2",
   "metadata": {},
   "source": [
    "# PACT resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fc2040c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "from module import ActFn, Conv2d, Linear\n",
    "from torch.autograd import Variable\n",
    "\n",
    "__all__ = ['ResNet', 'resnet20', 'resnet34', \"resnet50\"]\n",
    "\n",
    "def _weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    #print(classname)\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight)\n",
    "\n",
    "class LambdaLayer(nn.Module):\n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)\n",
    "\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, k=8, expansion=1, snr=0.1, inference=False, res50=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.k = k\n",
    "        self.expansion = expansion\n",
    "        self.res50 = res50\n",
    "        \n",
    "        if not res50:\n",
    "            self.conv1 = Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False, bitwidth = k, noise=snr, inference=inference)\n",
    "            self.bn1 = nn.BatchNorm2d(planes)           \n",
    "            self.conv2 = Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False, bitwidth = k, noise=snr, inference=inference)\n",
    "            self.bn2 = nn.BatchNorm2d(planes)\n",
    "        else:\n",
    "            # 1x1, 3x3, 1x1 block\n",
    "            outchannel = planes\n",
    "            inchannel = in_planes\n",
    "            channel = outchannel//4            \n",
    "            # 1x1 conv\n",
    "            self.conv1 = nn.Conv2d(inchannel, channel, 1)\n",
    "            self.bn1 = nn.BatchNorm2d(channel)\n",
    "            self.relu1 = nn.ReLU(True)\n",
    "            # 3x3 conv\n",
    "            self.conv2 = nn.Conv2d(channel, channel, 3, padding=1, stride=stride,)\n",
    "            self.bn2 = nn.BatchNorm2d(channel)\n",
    "            self.relu2 = nn.ReLU(True)\n",
    "            # 1x1 conv\n",
    "            self.conv3 = nn.Conv2d(channel, outchannel, 1)\n",
    "            self.bn3 = nn.BatchNorm2d(outchannel)\n",
    "            self.relu3 = nn.ReLU(True)\n",
    "        \n",
    "        # PACT\n",
    "        self.alpha1 = nn.Parameter(torch.tensor(10.))\n",
    "        self.alpha2 = nn.Parameter(torch.tensor(10.))\n",
    "        self.ActFn = ActFn.apply\n",
    "        self.snr = snr\n",
    "\n",
    "        if stride != 1 or in_planes != planes:\n",
    "              # original resnet shortcut\n",
    "              self.shortcut = nn.Sequential(\n",
    "                    # nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                    Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                    nn.BatchNorm2d(self.expansion * planes)\n",
    "              )\n",
    "        else: # nothing done if stride or inplanes do not differ\n",
    "          self.shortcut = nn.Sequential()\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not self.res50:\n",
    "            out = self.ActFn(self.bn1(self.conv1(x)), self.alpha1, self.k)\n",
    "            out = self.bn2(self.conv2(out))\n",
    "        else:\n",
    "            # 1x1\n",
    "            out = self.relu1(self.bn1(self.conv1(x)))\n",
    "            # 3x3\n",
    "            out = self.relu2(self.bn2(self.conv2(out)))\n",
    "            # 1x1\n",
    "            out = self.bn3(self.conv3(out))\n",
    "        # residue\n",
    "        out += self.shortcut(x)\n",
    "        out = self.ActFn(out, self.alpha2, self.k)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10, K=8, snr=0, inference=False, conv1_noise=True, linear_noise=True, res50=False):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "        self.k = K\n",
    "        self.snr = snr\n",
    "        self.inference = inference\n",
    "        self.res50 = res50\n",
    "\n",
    "        # 1st layers\n",
    "        self.conv1 = Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False, bitwidth = 8, noise=snr*float(conv1_noise), inference=inference)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.alpha1 = nn.Parameter(torch.tensor(10.))\n",
    "        self.ActFn = ActFn.apply\n",
    "        \n",
    "        # Blocks\n",
    "        if not res50:\n",
    "            self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1, expansion=1)\n",
    "            self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2, expansion=1)\n",
    "            self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2, expansion=1)\n",
    "            self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2, expansion=1)\n",
    "        else:\n",
    "            self.layer1 = self._make_layer(block, 256, num_blocks[0], stride=1, expansion=1)\n",
    "            self.layer2 = self._make_layer(block, 512, num_blocks[1], stride=2, expansion=1)\n",
    "            self.layer3 = self._make_layer(block, 1024, num_blocks[2], stride=2, expansion=1)\n",
    "            self.layer4 = self._make_layer(block, 2048, num_blocks[3], stride=2, expansion=1)\n",
    "        \n",
    "        # FCs\n",
    "        if not res50:\n",
    "            self.linear = Linear(512, num_classes, bitwidth = 8, noise=snr*float(linear_noise), inference=inference)\n",
    "        else:\n",
    "            self.linear = Linear(2048, num_classes, bitwidth = 8, noise=snr*float(linear_noise), inference=inference)\n",
    "        self.apply(_weights_init)       \n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride, expansion):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride, self.k, expansion, self.snr, inference=self.inference, res50=self.res50))\n",
    "            self.in_planes = planes * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.ActFn(self.bn1(self.conv1(x)), self.alpha1, self.k)\n",
    "        # layers\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, out.size()[3])\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cd0a7f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(BasicBlock, [3, 4, 6, 3], res50=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ea455846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-6.1927,  7.8933, -1.7759,  5.1656, -1.0439, -3.0961, -5.2665,  5.1290,\n",
       "         18.7735,  5.0228]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.rand(1,3,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a28334d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
